# 相机（Camera）

## 认识相机

- 相机的核心是传感器，此处围绕传感器展开。
- 当今的传感器上一般还有两层重要的结构（其实还有更多，例如红外截止滤镜等，但此处不讨论），低通滤镜（较外层）和拜尔滤镜（紧贴传感器）。
- 传感器可以认为是若干个光敏半导体颗粒排列而成的，通过统计上面产生的电荷量，就可以推测打在其上的光子个数。
- 但传感器不能分辨光的颜色。由于相机是为人服务的，人眼的三原色是红、绿、蓝，因此人们制作了对应颜色的滤镜，使得每个像素点仅记录一种颜色的亮度。又由于人眼对绿色更为敏感，因此绿色像素数较多。
- 因此实际上每个像素对应的另外两种颜色是由临近的该种颜色计算出来的。
- 也就是说 1200 万像素的传感器，只有 300 万个完整的 RGGB 像素阵列。
- CMOS 的每个像素由开关控制开始曝光和读出数值（但不能控制结束曝光）。例如你可以控制像素对应的电子数一直为0，此时不会被光改变。当不控制电子时即为开始曝光，而读出时只能立即读出当前值。
- 传统的 CMOS 需要逐个像素读出（实际上一行内是很快的，但行与行之间的时间差是肉眼可见的）。
- 部分先进的 CMOS 可以同时读出整块 CMOS 上的数值。
- 传统 CMOS 会出现果冻效应。考虑一个物体在从左向右运动，CMOS由于读出每行需要一定的时间，又要保证每个像素的曝光时间一致，因此下面的行整体而言曝光就要比上面的行延后。因此实际拍摄时，在下一行曝光时，物体总是比上一行曝光时向右移动了一些，这就导致了出现明明是竖直的物体变斜的情况。
- 在部分机器，整块 CMOS 可以通过位移来达到（部分，并非完全）抵消机身抖动的效果。

## 快门速度

- 传感器每个像素接收光线的时间越长，$f(a)=f(b)$就可以捕获更多光子。这个时间不宜过长也不宜过短，一般为曝光每秒帧速率 2 倍的倒数。例如每秒 30 帧的视频，曝光时间为 1/60 秒左右为宜。简单而言，曝光过长会导致画面“拖影”严重，而过短画面会出现不连贯感。以下为两个注意事项：
- “人眼的帧率”。我们常说人眼是每秒 24 帧，每秒 24 帧是可以在人眼实现连贯的画面的最小值，超过每秒 24 帧的画面一定会比每秒 24 帧更流畅，据我身边人反映，一般在观看视频时，每秒 100 帧以上的帧速率才会出现比较明显的边界效应。以我的想法，人眼更像是一个滑动窗口。人眼任意时刻反映的的亮度实际上是：
- 设任意时刻光强为 $f\left ( t \right )$，当前时刻为 ${t}_{0}$，则当前人眼反映亮度应该是

$$ \int ^{{t}_{0}}_{{t}_{0}-1s/24} {f\left ( {t} \right )g\left ( {{t}_{0}-t} \right )dt} $$

其中 $g\left ( {x} \right )$ 在 $\left [ {0,\, 1s/24} \right ]$ 上单调递减，且 $g\left ( {x} \right )\to 0\left ( {x\to \frac {1s} {24}} \right )$。

### 工频防闪烁
- 工频防闪烁有两种做法，一种是帧间隔为半周期的整数倍，一种是快门时间为半周期的整数倍。两种方式在 50Hz 正弦波光源下的原理如图解释（其中涂色为每次曝光接收到的光，面积均应相同以保证每一帧亮度相同）。第一种按 50fps，每次曝光 1/1000s，第二种按 60fps，每次曝光 1/100s。
- 第一种方式的弊端：仅限帧率为市电频率2倍除以整数时可使用。第一帧的开始时间不同，画面亮度会有差异。
- 第一种方式的优点：
- 快门速度可以缩得很小

